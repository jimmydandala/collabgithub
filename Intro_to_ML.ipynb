{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BldwbxIOMPS2"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u66nBUOCMTbi"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "  filepath_or_buffer='https://raw.githubusercontent.com/aaronmcdaid/P2---Data-Analytics-With-Python/master/Berlin/WS%202019/5.%20Datasets/titanic_dataset/train.csv',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "HhGthd6pNFFp",
    "outputId": "accb09f7-7058-4a64-aecf-b06414c914db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  ...     Fare Cabin  Embarked\n",
       "0            1         0       3  ...   7.2500   NaN         S\n",
       "1            2         1       1  ...  71.2833   C85         C\n",
       "2            3         1       3  ...   7.9250   NaN         S\n",
       "3            4         1       1  ...  53.1000  C123         S\n",
       "4            5         0       3  ...   8.0500   NaN         S\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "colab_type": "code",
    "id": "e9AAIdLkNGOF",
    "outputId": "dd13ced3-62dc-4c64-a932-6dbe14f4d871"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    891\n",
       "Survived       891\n",
       "Pclass         891\n",
       "Name           891\n",
       "Sex            891\n",
       "Age            714\n",
       "SibSp          891\n",
       "Parch          891\n",
       "Ticket         891\n",
       "Fare           891\n",
       "Cabin          204\n",
       "Embarked       889\n",
       "Name: count, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a quick overview of the dataset (ideally we'd do a lot more here, but for simplicity's sake)\n",
    "df.describe(include='all').loc['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386
    },
    "colab_type": "code",
    "id": "TQRnOAQgi43o",
    "outputId": "13b41635-0807-447f-ade9-ead097754fd5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>148</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sage, Miss. Stella Anna</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1601</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unknown</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>687</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass  ...        Fare    Cabin  Embarked\n",
       "count    891.000000  891.000000  891.000000  ...  891.000000      891       889\n",
       "unique          NaN         NaN         NaN  ...         NaN      148         3\n",
       "top             NaN         NaN         NaN  ...         NaN  unknown         S\n",
       "freq            NaN         NaN         NaN  ...         NaN      687       644\n",
       "mean     446.000000    0.383838    2.308642  ...   32.204208      NaN       NaN\n",
       "std      257.353842    0.486592    0.836071  ...   49.693429      NaN       NaN\n",
       "min        1.000000    0.000000    1.000000  ...    0.000000      NaN       NaN\n",
       "25%      223.500000    0.000000    2.000000  ...    7.910400      NaN       NaN\n",
       "50%      446.000000    0.000000    3.000000  ...   14.454200      NaN       NaN\n",
       "75%      668.500000    1.000000    3.000000  ...   31.000000      NaN       NaN\n",
       "max      891.000000    1.000000    3.000000  ...  512.329200      NaN       NaN\n",
       "\n",
       "[11 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J3bt8-g2CHd1"
   },
   "outputs": [],
   "source": [
    "# Seems like both Age, Cabin and Embarked have missing data\n",
    "# We'll just fill the nulls with what we call \"uninformative priors\"\n",
    "# i.e. we have no clue, so we want those numbers to  not bias the model\n",
    "\n",
    "# For a numerical feature, that is the median\n",
    "\n",
    "df.Age = df.Age.fillna(\n",
    "    df.Age.median()\n",
    ")\n",
    "\n",
    "# For a categorical, that is the mode (most common category)\n",
    "df.Embarked = df.Embarked.fillna(\n",
    "    df.Embarked.mode()\n",
    ")\n",
    "\n",
    "# Finally, for the cabin we have no clue at all so we call it unknown so it doesn't bug us\n",
    "# We won't use this column for much anyway\n",
    "\n",
    "df.Cabin = df.Cabin.fillna(\"unknown\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vmj-sfN8N7ja"
   },
   "source": [
    "# Welcome to Machine Learning!\n",
    "\n",
    "Today we will go over a basic (basic!) Machine Learning pipeline from dataset to prediction.\n",
    "\n",
    "We have the (in)famous Titanic dataset, and with that, we want you to try to predict who made it home from the wreckage, basically, who `Survived == True`\n",
    "\n",
    "## How this class will be structured\n",
    "\n",
    "We will start from the very basic, and then start building a pipeline incrementally. There's only one rule: After the first time we run the model, every cell must produce a prediction.\n",
    "\n",
    "Why? Because this is how we (PM's, the annoying people in your team) will push you to work. Deliver a working (not perfect) model every time, and grow incrementally.\n",
    "\n",
    "Here's what we'll do:\n",
    "\n",
    "1. Short theoretical introduction (trust me, you'll need it)\n",
    "1. Create, train and validate our first model step by step\n",
    "1. Evaluate the results, how do we feel about them?\n",
    "1. Enhancement: Feature engineering! and re-run\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84cO_eqFQSri"
   },
   "source": [
    "## Create, train and validate our first machine learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kdx9GPJ_RNpa"
   },
   "source": [
    "### First, we need a model to train\n",
    "\n",
    "Models have different applications, and as you grow into the field you'll understand them better.\n",
    "\n",
    "For this example, we will use a very generic and powerful classifier: the random forest.\n",
    "\n",
    "For any model you usually have to define a few parameters. Since they will be constant throughout most of the training process, we call them **Hyperparameters**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wk0wais2QXaB"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, # Hyperparameter 1\n",
    "    max_depth=2,      # Hyperparameter 2\n",
    "    random_state=0    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "C6Lk_buLRqad",
    "outputId": "1a1f7b77-b4a5-4532-da18-e90700b71bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model # As you can see, there's many more hyperparameters that were defined for us\n",
    "      # While it helps to understand what all of those do, you can get very far with predefined ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BbkIqV2XSS1p"
   },
   "source": [
    "Do you see any reference to df anywhere in that code?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L0mTnea-SA5W"
   },
   "source": [
    "### Second, we need data to train it on\n",
    "\n",
    "Scikit-Learn has a standard interface for all models\n",
    "\n",
    "```\n",
    "model.fit(X, y)\n",
    "```\n",
    "\n",
    "Will take a generic model and some training data and return a trained model. A trained model can do predicitions that will (maybe) make sense.\n",
    "\n",
    "X is a dataset of **FEATURES**, the data that we will use to predict stuff\n",
    "\n",
    "y is a single column of **TARGETS**, the correct answers we want the model to learn how to generate\n",
    "\n",
    "Sice this interface is predefined and we cannot really change it, we will need to take X and y out of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mp-QXjn1RtEv"
   },
   "outputs": [],
   "source": [
    "# For our first iteration, we will try to predict survival based on four variables:\n",
    "predictors = [\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "]\n",
    "\n",
    "# One last thing (technicality), let's drop all null rows for now\n",
    "\n",
    "X = df[predictors]\n",
    "\n",
    "y = df['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "TchIUXrJUFLj",
    "outputId": "807241db-58ac-43cc-bc04-2c693f88e057"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SibSp  Parch\n",
       "0      1      0\n",
       "1      1      0\n",
       "2      0      0\n",
       "3      1      0\n",
       "4      0      0"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "KM6YiAaIUF1y",
    "outputId": "7a47370b-b811-401f-fff0-5f446f457278"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GmX0mSRcUG5p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HAYZtjBQUVNn"
   },
   "source": [
    "### Now to the magic, let's train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xPB5VXcJUdJB"
   },
   "outputs": [],
   "source": [
    "trained_model = model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "CvXnS7yCUgxw",
    "outputId": "095cbced-bcac-4d46-f514-fbe6105ecd8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model # As we can see, nothign seems to have changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 728
    },
    "colab_type": "code",
    "id": "EBANiH1-UwWp",
    "outputId": "3daf5a93-6158-4391-f1e5-dbf21465cb15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But if we give it a dataset with some input values for the predictors, it can predict  if they survived or not!\n",
    "trained_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HP2h5vl-VgKf"
   },
   "outputs": [],
   "source": [
    "# And that is our prediction... uhm, okay?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujnCueBTVhik"
   },
   "source": [
    "### How do we know this worked?\n",
    "\n",
    "We know who survived (we have that in the variable called `y`, remember?) so we can just check how many hits it had"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjR8hlDbVTvQ"
   },
   "outputs": [],
   "source": [
    "y_predict = trained_model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "u791kOTNV5MI",
    "outputId": "52e0e914-ab52-4d6a-c7c1-665ad0fbbdff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     596\n",
       "False    295\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_predict == y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "k7B7Lv6gnRj4",
    "outputId": "d654b97f-055f-4896-c7f5-baa450dc71ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6689113355780022"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "596/(596+295)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tyIq0JljWDox"
   },
   "source": [
    "Do you trust this to be a good metric for whether the model is predicting well?\n",
    "\n",
    "Remember we trained it to return those exact values (y) for that exact input (X), so if the model was big enough it could theoretically match everything perfectly.\n",
    "\n",
    "See:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "r4Bf3fSfV7Ci",
    "outputId": "10b84510-1e01-458b-e91b-57d906ae2e58"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     604\n",
       "False    287\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_huge = RandomForestClassifier(n_estimators=10000, max_depth=200)\n",
    "(model_huge.fit(X, y).predict(X) == y).value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtjCGaZcWrVe"
   },
   "source": [
    "If we keep making it bigger it will probably fit the data even better (and also take a handful of hours to run so trust me here)\n",
    "\n",
    "So a huge model solves all of our problems!? Right!?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**OF COURSE NOT :D**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoQzRcGiW6yj"
   },
   "source": [
    "### So how do we actually know this thing works?\n",
    "\n",
    "To verify that a model is accurately predicting y from X in the phenomenon that you're trying to explain, you need to use a *train-test split*\n",
    "\n",
    "You use a subset of the data for training the model, and another one to verify it got it right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fVETPZc6XVCH"
   },
   "source": [
    "## Let's start again from the data extraction part\n",
    "\n",
    "\n",
    "\n",
    "This time we'll get it right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bx6FvA2hWhX1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=111) \n",
    "\n",
    "# A few things happening here in case you're curious:\n",
    "\n",
    "  # WTF is this comma-separated assignnment?\n",
    "    # The function will return a tuple with the train/test splits of X and y like\n",
    "    # (X_train, X_test, y_train, y_test), when we put them separated by commas in\n",
    "    # this way we are \"unpacking the tuple\" into separate variables\n",
    "\n",
    "  # WTF is this random_state thing?\n",
    "    # This function will randomise the dataset and split it into train and test\n",
    "    # We want to make this cell produce the same output every time\n",
    "    # This number is the \"seed\" for the randomiser, and as it is always the same\n",
    "    # the order is random but it is always the same\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "przJ8pLXY7J5"
   },
   "source": [
    "#### Now back to training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "MAykNx3RXwtY",
    "outputId": "be6be230-b1fb-4479-8091-fa737cb0d1cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     146\n",
       "False     77\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000, # Hyperparameter 1\n",
    "    max_depth=2,      # Hyperparameter 2\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "traied_model = model.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = trained_model.predict(X_test)\n",
    "\n",
    "(test_predictions == y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GKvq913cZXsy",
    "outputId": "f552123e-5209-48e1-c951-456ab69bcc15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6547085201793722"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "146 / (146+77) # This gives our model an accuracy (on this very simple iteration) of 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8x3i84xZjyW"
   },
   "outputs": [],
   "source": [
    "# Is that good? Let's use the Monkey Predictor Model and see if it performs better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "EpybS3mvZ54g",
    "outputId": "856fae27-fd4b-4c3e-cc2f-b698d32ae6ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: This function is deprecated. Please call randint(0, 1 + 1) instead\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True     116\n",
       "False    107\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.random import random_integers\n",
    "\n",
    "def monkey_model_predict(X):\n",
    "  return random_integers(0,1,X.shape[0])\n",
    "(monkey_model_predict(X_test) == y_test).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jD03KOzfa99-",
    "outputId": "ad3da1c7-ca63-4fca-a7af-60fd91abdf18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5201793721973094"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "116/(116+107)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TD1A7HaKb-ds"
   },
   "source": [
    "In a classification problem, your target accuracy is to significantly beat random chance.\n",
    "\n",
    "If a monkey tapping on buttons randomly can better predict your target than your model, you just wasted your time :)\n",
    "\n",
    "BTW, this happens a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJBFk4dqcbEp"
   },
   "source": [
    "## Let's make this model better!\n",
    "\n",
    "Now we know how to build and test a model (veeeeery simply). Now let's make it better.\n",
    "\n",
    "Where should we start?\n",
    "\n",
    "- Get a more powerful model?\n",
    "- Get better data?\n",
    "\n",
    "For that, we need to think like analysts:\n",
    "- Is the data that I'm giving it likely to explain what I want to predict?\n",
    "  - Think like a human (job security!): Is the number of siblings or parents likely to predict your survival?\n",
    "  - The answer is probably no, so let's explore the dataset a bit more to find any good predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8jM4nDwndKMQ"
   },
   "outputs": [],
   "source": [
    "# Do that here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UyKWxS0ndMxz",
    "outputId": "8289a428-f3a3-4809-da81-a68027a526d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6604477611940298"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predictors = [\n",
    "    \"Fare\",\n",
    "    \"Age\"\n",
    "]\n",
    "\n",
    "X = df[predictors]\n",
    "\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    random_state=111\n",
    "    \n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=1000, # Hyperparameter 1\n",
    "    max_depth=2,      # Hyperparameter 2\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "trained_model = model.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = trained_model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O2nmiNQ2d6s5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RStaLm_6amOR"
   },
   "source": [
    "### Why can I not use categorical variables?\n",
    "\n",
    "The model that we're using (and actually most scikit-learn models) only work with numerical data. But worry not! We can use all variables with a bit of pre-processing ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "eZw3fyB1bDOi",
    "outputId": "23e727e5-3208-440b-faa4-9e6b59158bf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonull.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WHhGLqrMa3Up",
    "outputId": "ce1f6ec9-8e4e-4912-aaf3-4c8ad7b5d15f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8246268656716418"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "df['is_child'] = df.Age < 16\n",
    "\n",
    "categorical_predictors = [\n",
    "    'Sex',\n",
    "    'is_child',\n",
    "    'Pclass'\n",
    "    \n",
    "]\n",
    "\n",
    "\n",
    "numeric_predictors = [\n",
    "    'SibSp',\n",
    "    'Parch',\n",
    "    'Age',\n",
    "    'Fare'\n",
    "]\n",
    "\n",
    "categorical_encoder = OneHotEncoder(\n",
    "    sparse=False\n",
    ")\n",
    "\n",
    "X_not_transformed = df[categorical_predictors]\n",
    "\n",
    "X_cat = categorical_encoder.fit_transform(\n",
    "    X_not_transformed\n",
    ") # This is now going to be a numpy array, as scikit-learn will strip out all the indexing magic\n",
    "\n",
    "X_num = df[numeric_predictors].values\n",
    "\n",
    "X = np.concatenate([\n",
    "    X_cat,\n",
    "    X_num\n",
    "], axis=1)\n",
    "\n",
    "y = df[\"Survived\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    y, \n",
    "    random_state=11,\n",
    "    test_size=0.3\n",
    ")\n",
    "\n",
    "RandomForestClassifier(\n",
    "    n_estimators=1000, # Hyperparameter 1\n",
    "    max_depth=2,      # Hyperparameter 2\n",
    "    random_state=1\n",
    ")\\\n",
    "  .fit(X_train, y_train)\\\n",
    "  .score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_8qZPvW8DSm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting juypterthemes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement juypterthemes (from versions: none)\n",
      "ERROR: No matching distribution found for juypterthemes\n"
     ]
    }
   ],
   "source": [
    "! pip install juypterthemes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! jt -t<"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Kdx9GPJ_RNpa",
    "L0mTnea-SA5W",
    "HAYZtjBQUVNn",
    "ujnCueBTVhik"
   ],
   "name": "Copy of Lecture 12 â€“ Intro to ML",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
